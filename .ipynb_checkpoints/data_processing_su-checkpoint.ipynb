{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2eaaa729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import itertools\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3fd85177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  district  year case  fire_count\n",
      "0      ê°•ë‚¨êµ¬  2006   ê¸°íƒ€        50.0\n",
      "1      ê°•ë‚¨êµ¬  2006   ë°©í™”        27.0\n",
      "2      ê°•ë‚¨êµ¬  2006   ì†Œê³„       296.0\n",
      "3      ê°•ë‚¨êµ¬  2006   ì‹¤í™”       219.0\n",
      "4      ê°•ë‚¨êµ¬  2007   ê¸°íƒ€        54.0\n",
      "5      ê°•ë‚¨êµ¬  2007   ë°©í™”        27.0\n",
      "6      ê°•ë‚¨êµ¬  2007   ì†Œê³„       265.0\n",
      "7      ê°•ë‚¨êµ¬  2007   ì‹¤í™”       184.0\n",
      "8      ê°•ë‚¨êµ¬  2008   ê¸°íƒ€        17.0\n",
      "9      ê°•ë‚¨êµ¬  2008   ë°©í™”        53.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_19284\\858157124.py:24: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  .stack(level=[0, 2])                    # level 0=ì—°ë„, 2=case\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# â”€â”€ 1. ê²½ë¡œ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "SRC = Path(\"data/raw_data/fire_data.csv\")   # Wide ì›ë³¸\n",
    "DST = Path(\"data/first_processing_data/fire_tidy_cases.csv\")         # Long ê²°ê³¼\n",
    "\n",
    "# â”€â”€ 2. CSV ë¡œë“œ : í—¤ë” 3ì¤„ë¡œ MultiIndex ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "wide = pd.read_csv(SRC, header=[0, 1, 2], dtype=str)\n",
    "\n",
    "# â”€â”€ 3. ìì¹˜êµ¬ ì»¬ëŸ¼(ë™ë³„(2)â€¦)ê³¼ â€œë°œìƒ (ê±´)â€ ì»¬ëŸ¼ë§Œ ì„ íƒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#     Â· ìì¹˜êµ¬ = ('ë™ë³„(2)','ë™ë³„(2)','ë™ë³„(2)')\n",
    "#     Â· fire_cols = [(YYYY, 'ë°œìƒ (ê±´)', case)]\n",
    "district_col = ('ë™ë³„(2)', 'ë™ë³„(2)', 'ë™ë³„(2)')\n",
    "fire_cols = [c for c in wide.columns if c[1] == 'ë°œìƒ (ê±´)']\n",
    "\n",
    "# â”€â”€ 4. â€˜í•©ê³„/ì†Œê³„â€™ í–‰ ì œê±°, ì¸ë±ìŠ¤ = district â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df = (\n",
    "    wide[wide[district_col] != 'ì†Œê³„']      # ì „ì²´ í•©ê³„ í–‰ ì œê±°\n",
    "    [ [district_col] + fire_cols ]          # í•„ìš”í•œ ì—´ë§Œ\n",
    "    .set_index(district_col)                # í–‰ ì¸ë±ìŠ¤ = ìì¹˜êµ¬\n",
    ")\n",
    "\n",
    "# â”€â”€ 5. Wide âœ Long (stack) : ì—°ë„Â·case ë‘ ì¶•ì„ í–‰ìœ¼ë¡œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "tidy = (\n",
    "    df\n",
    "    .stack(level=[0, 2])                    # level 0=ì—°ë„, 2=case\n",
    "    .reset_index()\n",
    ")\n",
    "tidy.columns = ['district', 'year', 'case', 'fire_count']\n",
    "\n",
    "# â”€â”€ 6. ê°’ ì „ì²˜ë¦¬ : â€˜-â€™â†’NaN, ì‰¼í‘œ ì œê±°, (ì›í•˜ë©´ intí˜•) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "tidy['fire_count'] = (\n",
    "    tidy['fire_count']\n",
    "        .replace('-', np.nan)\n",
    "        .str.replace(',', '', regex=False)\n",
    "        .astype(float)        # í•„ìš”í•˜ë©´ .astype('Int64') ë¡œ ì •ìˆ˜\n",
    ")\n",
    "\n",
    "# â”€â”€ 7. ì •ë ¬Â·ì €ì¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "tidy = tidy.sort_values(['district', 'year', 'case']).reset_index(drop=True)\n",
    "tidy.to_csv(DST, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(tidy.head(10))  # ê²°ê³¼ í™•ì¸ìš© ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "348d4e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  district    metric  year weather  count\n",
      "0       ì†Œê³„  ë°œìƒê±´ìˆ˜ (ê±´)  2013       ëˆˆ    322\n",
      "1       ì†Œê³„  ë°œìƒê±´ìˆ˜ (ê±´)  2013      ë§‘ìŒ  33287\n",
      "2       ì†Œê³„  ë°œìƒê±´ìˆ˜ (ê±´)  2013       ë¹„   3019\n",
      "3       ì†Œê³„  ë°œìƒê±´ìˆ˜ (ê±´)  2013      ì•ˆê°œ      9\n",
      "4       ì†Œê³„  ë°œìƒê±´ìˆ˜ (ê±´)  2013      íë¦¼   2329\n",
      "5       ì†Œê³„  ë°œìƒê±´ìˆ˜ (ê±´)  2014       ëˆˆ    302\n",
      "6       ì†Œê³„  ë°œìƒê±´ìˆ˜ (ê±´)  2014      ë§‘ìŒ  35339\n",
      "7       ì†Œê³„  ë°œìƒê±´ìˆ˜ (ê±´)  2014       ë¹„   2463\n",
      "8       ì†Œê³„  ë°œìƒê±´ìˆ˜ (ê±´)  2014      ì•ˆê°œ      7\n",
      "9       ì†Œê³„  ë°œìƒê±´ìˆ˜ (ê±´)  2014      íë¦¼   2011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_19284\\4133732463.py:24: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  .stack(level=[0, 2])                       # ì—°ë„ + ë‚ ì”¨ ë ˆë²¨ë§Œ ë…¹ì—¬ í–‰ìœ¼ë¡œ\n"
     ]
    }
   ],
   "source": [
    "# 1) CSV â†’ MultiIndex DataFrame\n",
    "df = pd.read_csv(\n",
    "    'data/raw_data/weather_accident.csv',\n",
    "    header=[0, 1, 2]                # ìƒë‹¨ 3ì¤„ì´ ë ˆë²¨0Â·1Â·2\n",
    ")\n",
    "\n",
    "# 2) ìì¹˜êµ¬Â·í•­ëª© ì»¬ëŸ¼ í‚¤ ì°¾ê¸°\n",
    "cols = df.columns\n",
    "district_key = next(\n",
    "    k for k in cols\n",
    "    if k[0].startswith('ìì¹˜êµ¬ë³„') and k[0] == k[1] == k[2] and k[0].endswith('(2)')\n",
    ")\n",
    "metric_key = next(k for k in cols if k[0] == k[1] == k[2] == 'í•­ëª©')\n",
    "\n",
    "# 3) â–¶ ì—°ë„(ë ˆë²¨0 ìˆ«ì 4ìë¦¬) ì»¬ëŸ¼ë§Œ ê³¨ë¼ë‘ê¸°\n",
    "year_regex = re.compile(r'^\\d{4}$')\n",
    "year_weather_cols = [k for k in cols if year_regex.match(str(k[0]))]\n",
    "\n",
    "# 4) â–¶ stack(level=[0,2]) : ì—°ë„(0), ë‚ ì”¨(2) ì¶•ì„ í–‰ìœ¼ë¡œ ë…¹ì„\n",
    "df_long = (\n",
    "    df\n",
    "    .set_index([district_key, metric_key])     # ìì¹˜êµ¬Â·í•­ëª©ì„ ì¸ë±ìŠ¤ë¡œ\n",
    "    [year_weather_cols]                        # ì—°ë„Â·ë‚ ì”¨ ì»¬ëŸ¼ë§Œ ëŒ€ìƒ\n",
    "    .stack(level=[0, 2])                       # ì—°ë„ + ë‚ ì”¨ ë ˆë²¨ë§Œ ë…¹ì—¬ í–‰ìœ¼ë¡œ\n",
    "    .reset_index()                             # ì¸ë±ìŠ¤ â†’ ì¼ë°˜ ì»¬ëŸ¼\n",
    ")\n",
    "\n",
    "# 5) ì»¬ëŸ¼ëª… ì •ë¦¬\n",
    "df_long.columns = ['district', 'metric', 'year', 'weather', 'count']\n",
    "\n",
    "# 6) â€˜ê¸°íƒ€/ë¶ˆëª…â€™ ì œì™¸, yearâ†’int\n",
    "df_long = (\n",
    "    df_long\n",
    "    .query(\"weather not in ['ê¸°íƒ€/ë¶ˆëª…', 'ì†Œê³„']\")\n",
    "    .assign(year=lambda x: x['year'].astype(int))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 7) ê²°ê³¼ í™•ì¸\n",
    "print(df_long.head(10))\n",
    "\n",
    "# 8) í•„ìš” ì‹œ ì €ì¥\n",
    "df_long.to_csv('data/first_processing_data/weather_tidy_data.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa8648a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë³€í™˜ ì™„ë£Œ: data/first_processing_data/Traffic_accidents_multi_metric_tidy.csv (2,850 rows)\n",
      "  district  year             metric   value\n",
      "0      ê°•ë‚¨êµ¬  2005           ë°œìƒê±´ìˆ˜ (ê±´)  3126.0\n",
      "1      ê°•ë‚¨êµ¬  2005           ë¶€ìƒììˆ˜ (ëª…)  4682.0\n",
      "2      ê°•ë‚¨êµ¬  2005           ì‚¬ë§ììˆ˜ (ëª…)    28.0\n",
      "3      ê°•ë‚¨êµ¬  2005  ì¸êµ¬ 10ë§Œëª…ë‹¹ ë¶€ìƒììˆ˜ (ëª…)   854.7\n",
      "4      ê°•ë‚¨êµ¬  2005  ì¸êµ¬ 10ë§Œëª…ë‹¹ ì‚¬ë§ììˆ˜ (ëª…)     5.1\n",
      "5      ê°•ë‚¨êµ¬  2005  ìë™ì°¨ 1ë§ŒëŒ€ë‹¹ ë°œìƒê±´ìˆ˜ (ê±´)   128.9\n",
      "6      ê°•ë‚¨êµ¬  2006           ë°œìƒê±´ìˆ˜ (ê±´)  3321.0\n",
      "7      ê°•ë‚¨êµ¬  2006           ë¶€ìƒììˆ˜ (ëª…)  4869.0\n",
      "8      ê°•ë‚¨êµ¬  2006           ì‚¬ë§ììˆ˜ (ëª…)    37.0\n",
      "9      ê°•ë‚¨êµ¬  2006  ì¸êµ¬ 10ë§Œëª…ë‹¹ ë¶€ìƒììˆ˜ (ëª…)   862.3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. íŒŒì¼ ê²½ë¡œ\n",
    "# ------------------------------------------------------------------\n",
    "SRC = \"data/raw_data/Traffic_accident_year_2005.csv\"     # ë‘ ë²ˆì§¸ CSV\n",
    "DST = \"data/first_processing_data/Traffic_accidents_multi_metric_tidy.csv\"     # ì²« ë²ˆì§¸ CSV êµ¬ì¡°ë¡œ ì €ì¥í•  íŒŒì¼\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. ì›ë³¸(ë‘ ë²ˆì§¸) CSV ì½ê¸° â”€â”€ â‘  ì²« í–‰ = â€œì—´ ê·¸ë£¹ ì´ë¦„â€, â‘¡ ë‘ ë²ˆì§¸ í–‰ = â€œì„¸ë¶€ í•­ëª©â€\n",
    "# ------------------------------------------------------------------\n",
    "raw = pd.read_csv(SRC, header=0, dtype=str)   # ì „ë¶€ ë¬¸ìì—´ë¡œ ì½ì–´ ë‘¡ë‹ˆë‹¤\n",
    "metric_header = raw.iloc[0]                   # í–‰ 0 : ê° ì—´ì— ëŒ€ì‘í•˜ëŠ” 'metric' ëª…ì¹­\n",
    "data = raw.iloc[1:].reset_index(drop=True)    # í–‰ 1ë¶€í„°ê°€ ì‹¤ì œ ë°ì´í„°\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. ìì¹˜êµ¬Â·ì†Œê³„Â·í•©ê³„ ì²˜ë¦¬\n",
    "#    - 'ìì¹˜êµ¬ë³„(2)'ê°€ ì‹¤ì œ ìì¹˜êµ¬\n",
    "#    - 'ì†Œê³„'Â·'í•©ê³„' í–‰ì€ ì œì™¸\n",
    "# ------------------------------------------------------------------\n",
    "data = (data\n",
    "        .rename(columns={\"ìì¹˜êµ¬ë³„(2)\": \"district\"})        # ìì¹˜êµ¬ ì´ë¦„ ì—´\n",
    "        .drop(columns=[\"ìì¹˜êµ¬ë³„(1)\"], errors=\"ignore\"))    # ìƒìœ„ ë¶„ë¥˜ ì—´ ì œê±°\n",
    "\n",
    "data = data[~data[\"district\"].isin([\"ì†Œê³„\", \"í•©ê³„\"])]       # í•©ê³„Â·ì†Œê³„ ì œì™¸\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. â€œì—°ë„Â·ì§€í‘œâ€ì— í•´ë‹¹í•˜ëŠ” ì—´ë§Œ ì¶”ì¶œ\n",
    "#    - ì—´ ì´ë¦„ì´ '1999' ë˜ëŠ” '1999.1' ê°™ì´ '^[0-9]{4}(?:\\.[0-9]+)?$' íŒ¨í„´\n",
    "# ------------------------------------------------------------------\n",
    "year_col_pattern = re.compile(r\"^\\d{4}(?:\\.\\d+)?$\")\n",
    "value_cols = [c for c in data.columns if year_col_pattern.match(c)]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5. ì—´  â†’ í–‰(long) ìœ¼ë¡œ ë³€í™˜\n",
    "#    - ê° ì—´ ì´ë¦„ì—ì„œ ì—°ë„(ìˆ«ì 4ìë¦¬) ì¶”ì¶œ\n",
    "#    - metric_headerì—ì„œ ê°™ì€ ì—´ ìœ„ì¹˜ì˜ â€˜metricâ€™ ëª…ì¹­ ì¶”ì¶œ\n",
    "#    - ê°’ì´ '-' ì¸ ì…€ì€ NaN ìœ¼ë¡œ ë°”ê¾¸ê³  float ë¡œ ë³€í™˜\n",
    "# ------------------------------------------------------------------\n",
    "records = []\n",
    "for col in value_cols:\n",
    "    year = int(col.split('.')[0])             # '1999.4' â†’ 1999\n",
    "    metric = metric_header[col]               # 'ë¶€ìƒììˆ˜ (ëª…)' ë“±\n",
    "    for dist, val in zip(data[\"district\"], data[col]):\n",
    "        if val == \"-\" or pd.isna(val):\n",
    "            continue                          # ê²°ì¸¡(â€˜-â€™)ì€ ë²„ë¦¼\n",
    "        try:\n",
    "            value = float(val.replace(\",\", \"\"))   # ì‰¼í‘œ ì œê±° í›„ ìˆ«ìí™”\n",
    "        except ValueError:\n",
    "            continue\n",
    "        records.append({\"district\": dist,\n",
    "                        \"year\": year,\n",
    "                        \"metric\": metric,\n",
    "                        \"value\": value})\n",
    "\n",
    "df_long = pd.DataFrame.from_records(records)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6. ì •ë ¬ Â· ìë£Œí˜• Â· ì €ì¥\n",
    "# ------------------------------------------------------------------\n",
    "df_long = (df_long\n",
    "           .astype({\"year\": \"int64\",\n",
    "                    \"value\": \"float64\"})\n",
    "           .sort_values([\"district\", \"year\", \"metric\"])\n",
    "           .reset_index(drop=True))\n",
    "\n",
    "df_long.to_csv(DST, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"âœ… ë³€í™˜ ì™„ë£Œ: {DST} ({len(df_long):,} rows)\")\n",
    "print(df_long.head(10))  # ê²°ê³¼ í™•ì¸ìš© ì¶œë ¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4df80d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: data\\first_processing_data\\Traffic_accidents_vehicle_tidy.csv (rows=525)\n",
      "     êµ¬    ì—°ë„   ìš©ë„  ë°œìƒê±´ìˆ˜  ì‚¬ìƒììˆ˜\n",
      "0  ê°•ë‚¨êµ¬  2017  ë²„ìŠ¤ê³„    96   146\n",
      "1  ê°•ë‚¨êµ¬  2017  ìŠ¹ìš©ê³„  2812  4122\n",
      "2  ê°•ë‚¨êµ¬  2017   í™”ë¬¼    60    90\n",
      "3  ê°•ë‚¨êµ¬  2018  ë²„ìŠ¤ê³„    81   120\n",
      "4  ê°•ë‚¨êµ¬  2018  ìŠ¹ìš©ê³„  2835  4181\n",
      "5  ê°•ë‚¨êµ¬  2018   í™”ë¬¼    49    63\n",
      "6  ê°•ë‚¨êµ¬  2019  ë²„ìŠ¤ê³„   104   132\n",
      "7  ê°•ë‚¨êµ¬  2019  ìŠ¹ìš©ê³„  2888  4155\n",
      "8  ê°•ë‚¨êµ¬  2019   í™”ë¬¼    63    88\n",
      "9  ê°•ë‚¨êµ¬  2020  ë²„ìŠ¤ê³„    84   103\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# â”€â”€â”€ ê²½ë¡œ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "SRC = Path(\"data/raw_data/Traffic_accidents_vehicle.csv\")  # ì›ë³¸ íŒŒì¼ ê²½ë¡œ\n",
    "DEST = Path(\"data/first_processing_data/Traffic_accidents_vehicle_tidy.csv\")  # ìµœì¢… ì €ì¥ ê²½ë¡œ\n",
    "\n",
    "# â”€â”€â”€ 1. ì›ë³¸ CSV ì½ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "wide = pd.read_csv(SRC, header=[0, 1, 2, 3, 4, 5], encoding=\"utf-8\")\n",
    "\n",
    "# â”€â”€â”€ 2. ìì¹˜êµ¬ ì¶”ì¶œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "dist_col = [c for c in wide.columns if c[0] == \"ìì¹˜êµ¬ë³„(2)\"][0]\n",
    "districts = wide[dist_col]\n",
    "\n",
    "# â”€â”€â”€ 3. ìœ íš¨í•œ ì»¬ëŸ¼ í•„í„°ë§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "year_pat = re.compile(r\"^\\d{4}$\")\n",
    "value_cols = [c for c in wide.columns if year_pat.match(c[0])]\n",
    "skip = {\"ì†Œê³„\", \"ìì¹˜êµ¬ë³„(1)\", \"ìì¹˜êµ¬ë³„(2)\", \"\"}\n",
    "records = []\n",
    "\n",
    "for idx, dist in districts.items():\n",
    "    if dist in {\"ì†Œê³„\", \"í•©ê³„\"}:\n",
    "        continue\n",
    "    for col in value_cols:\n",
    "        raw = wide.at[idx, col]\n",
    "        if raw in (\"-\", None) or pd.isna(raw):\n",
    "            continue\n",
    "        val = float(str(raw).replace(\",\", \"\"))\n",
    "        m5 = col[5]\n",
    "        if \"ë°œìƒê±´ìˆ˜\" in m5:\n",
    "            metric = \"acc\"\n",
    "        elif \"ì‚¬ë§ì\" in m5:\n",
    "            metric = \"fat\"\n",
    "        elif \"ë¶€ìƒì\" in m5:\n",
    "            metric = \"inj\"\n",
    "        else:\n",
    "            continue\n",
    "        for vt in (col[4], col[3], col[2]):\n",
    "            if vt not in skip:\n",
    "                vehicle = vt\n",
    "                break\n",
    "        else:\n",
    "            vehicle = col[2]\n",
    "        records.append({\n",
    "            \"ì—°ë„\": int(col[0]),\n",
    "            \"êµ¬\": dist,\n",
    "            \"ìš©ë„\": vehicle,\n",
    "            metric: val\n",
    "        })\n",
    "\n",
    "# â”€â”€â”€ 4. Tidy ë°ì´í„°í”„ë ˆì„ ìƒì„± ë° ì§‘ê³„ â”€â”€â”€â”€â”€â”€â”€\n",
    "df = pd.DataFrame(records).groupby([\"ì—°ë„\", \"êµ¬\", \"ìš©ë„\"], as_index=False).sum()\n",
    "\n",
    "# â”€â”€â”€ 5. ì œì™¸ ë° ì§‘ê³„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "drop_types = [\"ì‚¬ì—…ìš©ì°¨ëŸ‰\", \"ë¹„ì‚¬ì—…ìš©ì°¨ëŸ‰\", \"ê¸°íƒ€\", \"ê¸°íƒ€ë¶ˆëª…\", \"ì†Œê³„\", \"ì–´ë¦°ì´í†µí•™ë²„ìŠ¤\", \"ì´ë¥œì°¨\", \"ìì „ê±°\"]\n",
    "agg_map = {\n",
    "    \"ìŠ¹ìš©ê³„\": [\"ìŠ¹ìš©ì°¨\", \"ë Œí„°ì¹´\", \"íƒì‹œ\"],\n",
    "    \"ë²„ìŠ¤ê³„\": [\"ë²„ìŠ¤\", \"ì‹œë‚´ë²„ìŠ¤\", \"ì‹œì™¸,ê³ ì†ë²„ìŠ¤\", \"ì „ì„¸ë²„ìŠ¤\"]\n",
    "}\n",
    "df = df[~df[\"ìš©ë„\"].isin(drop_types)]\n",
    "\n",
    "rows = []\n",
    "for new_type, members in agg_map.items():\n",
    "    subset = df[df[\"ìš©ë„\"].isin(members)]\n",
    "    if not subset.empty:\n",
    "        summed = subset.groupby([\"êµ¬\", \"ì—°ë„\"], as_index=False)[[\"acc\", \"fat\", \"inj\"]].sum()\n",
    "        summed[\"ìš©ë„\"] = new_type\n",
    "        rows.append(summed)\n",
    "\n",
    "agg_df = pd.concat([df] + rows, ignore_index=True)\n",
    "\n",
    "# â”€â”€â”€ 6. ìµœì¢… ìš©ë„ í•„í„° ë° ì»¬ëŸ¼ ì •ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "keep = [\"ìŠ¹ìš©ê³„\", \"ë²„ìŠ¤ê³„\", \"í™”ë¬¼\"]\n",
    "agg_df = agg_df[agg_df[\"ìš©ë„\"].isin(keep)].copy()\n",
    "agg_df.rename(columns={\"acc\": \"ë°œìƒê±´ìˆ˜\", \"fat\": \"ì‚¬ë§ììˆ˜\", \"inj\": \"ë¶€ìƒììˆ˜\"}, inplace=True)\n",
    "\n",
    "for c in [\"ë°œìƒê±´ìˆ˜\", \"ì‚¬ë§ììˆ˜\", \"ë¶€ìƒììˆ˜\"]:\n",
    "    agg_df[c] = pd.to_numeric(agg_df[c], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "agg_df[\"ì‚¬ìƒììˆ˜\"] = agg_df[\"ì‚¬ë§ììˆ˜\"] + agg_df[\"ë¶€ìƒììˆ˜\"]\n",
    "\n",
    "# â”€â”€â”€ 7. ìµœì¢… ì •ë¦¬ ë° ì €ì¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "final = agg_df[[\"êµ¬\", \"ì—°ë„\", \"ìš©ë„\", \"ë°œìƒê±´ìˆ˜\", \"ì‚¬ìƒììˆ˜\"]].sort_values([\"êµ¬\", \"ì—°ë„\", \"ìš©ë„\"]).reset_index(drop=True)\n",
    "final.to_csv(DEST, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: {DEST} (rows={len(final):,})\")\n",
    "print(final.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ebaf1f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ: data\\first_processing_data\\Traffic_accidents_filtered_metrics.csv  (rows=1,425)\n",
      "   district  year             metric  value\n",
      "3       ê°•ë‚¨êµ¬  2005  ì¸êµ¬ 10ë§Œëª…ë‹¹ ë¶€ìƒììˆ˜ (ëª…)  854.7\n",
      "4       ê°•ë‚¨êµ¬  2005  ì¸êµ¬ 10ë§Œëª…ë‹¹ ì‚¬ë§ììˆ˜ (ëª…)    5.1\n",
      "5       ê°•ë‚¨êµ¬  2005  ìë™ì°¨ 1ë§ŒëŒ€ë‹¹ ë°œìƒê±´ìˆ˜ (ê±´)  128.9\n",
      "9       ê°•ë‚¨êµ¬  2006  ì¸êµ¬ 10ë§Œëª…ë‹¹ ë¶€ìƒììˆ˜ (ëª…)  862.3\n",
      "10      ê°•ë‚¨êµ¬  2006  ì¸êµ¬ 10ë§Œëª…ë‹¹ ì‚¬ë§ììˆ˜ (ëª…)    6.6\n",
      "11      ê°•ë‚¨êµ¬  2006  ìë™ì°¨ 1ë§ŒëŒ€ë‹¹ ë°œìƒê±´ìˆ˜ (ê±´)  132.3\n",
      "15      ê°•ë‚¨êµ¬  2007  ì¸êµ¬ 10ë§Œëª…ë‹¹ ë¶€ìƒììˆ˜ (ëª…)  849.6\n",
      "16      ê°•ë‚¨êµ¬  2007  ì¸êµ¬ 10ë§Œëª…ë‹¹ ì‚¬ë§ììˆ˜ (ëª…)    5.3\n",
      "17      ê°•ë‚¨êµ¬  2007  ìë™ì°¨ 1ë§ŒëŒ€ë‹¹ ë°œìƒê±´ìˆ˜ (ê±´)  128.6\n",
      "21      ê°•ë‚¨êµ¬  2008  ì¸êµ¬ 10ë§Œëª…ë‹¹ ë¶€ìƒììˆ˜ (ëª…)  790.1\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "SRC  = Path(\"data/first_processing_data/Traffic_accidents_multi_metric_tidy.csv\")  # ì—…ë¡œë“œí•˜ì‹  ì›ë³¸ íŒŒì¼\n",
    "DEST = Path(\"data/first_processing_data/Traffic_accidents_filtered_metrics.csv\")         # ì¶œë ¥ íŒŒì¼\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. CSV ë¶ˆëŸ¬ì˜¤ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df = pd.read_csv(SRC, dtype=str)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. ì›í•˜ëŠ” metricë§Œ í•„í„°ë§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "keep_metrics = [\n",
    "    \"ì¸êµ¬ 10ë§Œëª…ë‹¹ ë¶€ìƒììˆ˜ (ëª…)\",\n",
    "    \"ì¸êµ¬ 10ë§Œëª…ë‹¹ ì‚¬ë§ììˆ˜ (ëª…)\",\n",
    "    \"ìë™ì°¨ 1ë§ŒëŒ€ë‹¹ ë°œìƒê±´ìˆ˜ (ê±´)\"\n",
    "]\n",
    "filtered = df[df[\"metric\"].isin(keep_metrics)].copy()\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. ê²°ê³¼ ì €ì¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "filtered.to_csv(DEST, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"âœ… ì €ì¥ ì™„ë£Œ: {DEST}  (rows={len(filtered):,})\")\n",
    "\n",
    "print(filtered.head(10))  # ê²°ê³¼ í™•ì¸ìš© ì¶œë ¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4e2079c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ: data\\first_processing_data\\fire_count.csv  (rows=450)\n",
      "  district  year  í™”ì¬_ì†Œê³„\n",
      "0      ê°•ë‚¨êµ¬  2006    246\n",
      "1      ê°•ë‚¨êµ¬  2007    211\n",
      "2      ê°•ë‚¨êµ¬  2008    376\n",
      "3      ê°•ë‚¨êµ¬  2009    342\n",
      "4      ê°•ë‚¨êµ¬  2010    344\n",
      "5      ê°•ë‚¨êµ¬  2011    388\n",
      "6      ê°•ë‚¨êµ¬  2012    347\n",
      "7      ê°•ë‚¨êµ¬  2013    399\n",
      "8      ê°•ë‚¨êµ¬  2014    400\n",
      "9      ê°•ë‚¨êµ¬  2015    477\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "SRC  = Path(\"data/first_processing_data/fire_tidy_cases.csv\")  # ì—…ë¡œë“œí•˜ì‹  í™”ì¬ ë°ì´í„°\n",
    "DEST = Path(\"data/first_processing_data/fire_count.csv\")      # ì¶œë ¥ íŒŒì¼\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. CSV ë¶ˆëŸ¬ì˜¤ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df = pd.read_csv(SRC, dtype=str)\n",
    "\n",
    "# ìë™ìœ¼ë¡œ ì»¬ëŸ¼ëª… ì°¾ê¸° (í•„ìš”ì‹œ ì§ì ‘ ìˆ˜ì •)\n",
    "dist_col = next(c for c in df.columns if \"district\" in c or \"ìì¹˜êµ¬\" in c)\n",
    "year_col = next(c for c in df.columns if \"year\" in c or \"ì—°ë„\" in c)\n",
    "case_col = next(c for c in df.columns if \"case\" in c or \"êµ¬ë¶„\" in c)\n",
    "val_col  = next(c for c in df.columns if \"value\" in c or \"count\" in c or \"ê±´ìˆ˜\" in c)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. 'ë°©í™”', 'ì‹¤í™”' í–‰ë§Œ í•„í„°ë§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "mask = df[case_col].isin([\"ë°©í™”\", \"ì‹¤í™”\"])\n",
    "df_fs = df[mask].copy()\n",
    "\n",
    "# ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜\n",
    "df_fs[val_col] = pd.to_numeric(df_fs[val_col].str.replace(\",\", \"\"), errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. ë°©í™”+ì‹¤í™” í•©ì‚° â†’ í™”ì¬_ì†Œê³„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "agg = (\n",
    "    df_fs\n",
    "      .groupby([dist_col, year_col], as_index=False)[val_col]\n",
    "      .sum()\n",
    "      .rename(columns={val_col: \"í™”ì¬_ì†Œê³„\"})\n",
    ")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. ê²°ê³¼ ì €ì¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "agg.to_csv(DEST, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"âœ… ì €ì¥ ì™„ë£Œ: {DEST}  (rows={len(agg):,})\")\n",
    "\n",
    "print(agg.head(10))  # ê²°ê³¼ í™•ì¸ìš© ì¶œë ¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d09b6406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ: data\\first_processing_data\\weather_metrics_no_fog.csv  (rows=1,144)\n",
      "metric_key district  year weather    ë°œìƒê±´ìˆ˜    ì‚¬ìƒììˆ˜\n",
      "0               ê°•ë‚¨êµ¬  2013       ëˆˆ    25.0    33.0\n",
      "1               ê°•ë‚¨êµ¬  2013      ë§‘ìŒ  3099.0  4590.0\n",
      "2               ê°•ë‚¨êµ¬  2013       ë¹„   267.0   390.0\n",
      "4               ê°•ë‚¨êµ¬  2013      íë¦¼   159.0   255.0\n",
      "5               ê°•ë‚¨êµ¬  2014       ëˆˆ    30.0    58.0\n",
      "6               ê°•ë‚¨êµ¬  2014      ë§‘ìŒ  3280.0  4755.0\n",
      "7               ê°•ë‚¨êµ¬  2014       ë¹„   206.0   300.0\n",
      "9               ê°•ë‚¨êµ¬  2014      íë¦¼    89.0   145.0\n",
      "10              ê°•ë‚¨êµ¬  2015       ëˆˆ    15.0    22.0\n",
      "11              ê°•ë‚¨êµ¬  2015      ë§‘ìŒ  3569.0  5111.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "SRC  = Path(\"data/first_processing_data/weather_tidy_data.csv\")          # ì…ë ¥ íŒŒì¼ ê²½ë¡œ\n",
    "DEST = Path(\"data/first_processing_data/weather_metrics_no_fog.csv\")        # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. CSV ì½ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df = pd.read_csv(SRC, dtype=str)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. '-' ê°’ 0 ëŒ€ì²´ ë° ì‰¼í‘œ ì œê±° í›„ ìˆ«ì ë³€í™˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df[\"count\"] = df[\"count\"].replace(\"-\", \"0\").str.replace(\",\", \"\", regex=False).astype(int)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. ë°œìƒê±´ìˆ˜, ì‚¬ë§ì, ë¶€ìƒì í•„í„° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "metrics = {\n",
    "    \"ë°œìƒê±´ìˆ˜\": \"ë°œìƒê±´ìˆ˜ (ê±´)\",\n",
    "    \"ì‚¬ë§ììˆ˜\": \"ì‚¬ë§ì (ëª…)\",\n",
    "    \"ë¶€ìƒììˆ˜\": \"ë¶€ìƒì (ëª…)\"\n",
    "}\n",
    "# Rename metric values to consistent keys\n",
    "df_filtered = df[df[\"metric\"].isin(metrics.values())].copy()\n",
    "df_filtered[\"metric_key\"] = df_filtered[\"metric\"].map({v: k for k, v in metrics.items()})\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. ê·¸ë£¹ë³„ í•©ì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "agg = (\n",
    "    df_filtered\n",
    "      .groupby([\"district\", \"year\", \"weather\", \"metric_key\"], as_index=False)[\"count\"]\n",
    "      .sum()\n",
    ")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5. Pivot to wide format â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "pivoted = agg.pivot_table(\n",
    "    index=[\"district\", \"year\", \"weather\"],\n",
    "    columns=\"metric_key\",\n",
    "    values=\"count\",\n",
    "    fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 6. ì‚¬ìƒììˆ˜ ê³„ì‚° (ì‚¬ë§ììˆ˜ + ë¶€ìƒììˆ˜) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "pivoted[\"ì‚¬ìƒììˆ˜\"] = pivoted.get(\"ì‚¬ë§ììˆ˜\", 0) + pivoted.get(\"ë¶€ìƒììˆ˜\", 0)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 7. ì•ˆê°œ ì œì™¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "result = pivoted[pivoted[\"weather\"] != \"ì•ˆê°œ\"].copy()\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 8. ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬ ë° ì €ì¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "final = result[[\"district\", \"year\", \"weather\", \"ë°œìƒê±´ìˆ˜\", \"ì‚¬ìƒììˆ˜\"]]\n",
    "final.to_csv(DEST, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"âœ… ì €ì¥ ì™„ë£Œ: {DEST}  (rows={len(final):,})\")\n",
    "\n",
    "print(final.head(10))  # ê²°ê³¼ í™•ì¸ìš© ì¶œë ¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d46493e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ë™ë³„    ì—°ë„     ê±°ì£¼ì¸êµ¬\n",
      "0  ê°•ë‚¨êµ¬  2008  6829995\n",
      "1  ê°•ë‚¨êµ¬  2009  6828201\n",
      "2  ê°•ë‚¨êµ¬  2010  6862974\n",
      "3  ê°•ë‚¨êµ¬  2011  6909210\n",
      "4  ê°•ë‚¨êµ¬  2012  6835662\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1) CSV ì½ê¸°\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "file_path = \"data/raw_data/Resident_population_preprocessing.csv\"        # â† íŒŒì¼ ê²½ë¡œ(í•„ìš”í•˜ë©´ ìˆ˜ì •)\n",
    "df = pd.read_csv(file_path, encoding=\"utf-8\")\n",
    "\n",
    "# ì—´ ì´ë¦„ì— ë’¤ë”°ë¥¸ ê³µë°±ì´ ìˆì„ ìˆ˜ë„ ìˆì–´ ê¹”ë”í•˜ê²Œ\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 2) â€˜ì—°ì›”â€™ â†’ datetime ë³€í™˜ & â€˜ì—°ë„â€™ íŒŒìƒ\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df[\"ì—°ì›”\"] = pd.to_datetime(df[\"ì—°ì›”\"])      # ë¬¸ìì—´ â†’ Timestamp\n",
    "df[\"ì—°ë„\"] = df[\"ì—°ì›”\"].dt.year             # ì—°ë„ë§Œ ì¶”ì¶œ\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 3) í•„ìˆ˜ ì—´ ì¡´ì¬ í™•ì¸\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "required_cols = {\"ë™ë³„\", \"ê±°ì£¼ì¸êµ¬\", \"ì—°ë„\"}\n",
    "missing = required_cols - set(df.columns)\n",
    "if missing:\n",
    "    raise KeyError(f\"ë‹¤ìŒ ì—´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {missing}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 4) ë™Â·ì—°ë„ë³„ ê±°ì£¼ì¸êµ¬ í•©ì‚°\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "result = (df\n",
    "          .groupby([\"ë™ë³„\", \"ì—°ë„\"], as_index=False)[\"ê±°ì£¼ì¸êµ¬\"]\n",
    "          .sum()                              # ì›”ë³„ ê°’ â†’ ì—°ë„ í•©ê³„\n",
    "          .astype({\"ê±°ì£¼ì¸êµ¬\": \"int\"})        # ë³´ê¸° ì¢‹ê²Œ ì •ìˆ˜í˜•\n",
    "          .sort_values([\"ë™ë³„\", \"ì—°ë„\"]))      # ì •ë ¬(ì„ íƒ)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 5) ê²°ê³¼ í™•ì¸ ë˜ëŠ” ì €ì¥\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(result.head())                          # ì¼ë¶€ í™•ì¸\n",
    "result.to_csv(\"data/first_processing_data/Resident_population_preprocessing_year_sum.csv\",\n",
    "         index=False, encoding=\"utf-8-sig\")  # í•„ìš” ì‹œ íŒŒì¼ ì €ì¥\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "14066bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ìì¹˜êµ¬    ì—°ë„      ë²„ìŠ¤ìŠ¹ê°ìˆ˜   ì§€í•˜ì² _ìŠ¹ê°_ìˆ˜        ìŠ¹ê°ìˆ˜  ë°œìƒê±´ìˆ˜  ë¶€ìƒììˆ˜\n",
      "0  ê°•ë‚¨êµ¬  2017   94149570  146347253  241905699  3469  4959\n",
      "1  ê°•ë‚¨êµ¬  2018   98835925  148332567  249597367  3459  4967\n",
      "2  ê°•ë‚¨êµ¬  2019  100733693  153716474  256861504  3722  5182\n",
      "3  ê°•ë‚¨êµ¬  2020   96578579  153883394  251672041  3752  5189\n",
      "4  ê°•ë‚¨êµ¬  2021   98810029  157330951  257049406  3820  5175\n"
     ]
    }
   ],
   "source": [
    "# 1) CSV ì½ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "file_path = \"data/regression_data/passenger_data.csv\"   # ì‹¤ì œ íŒŒì¼ëª…/ê²½ë¡œ\n",
    "df = pd.read_csv(file_path, encoding=\"utf-8\")\n",
    "df.columns = df.columns.str.strip()         # ê³µë°± ì œê±°\n",
    "\n",
    "# 2) ë‚ ì§œ ì „ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df[\"ì—°ì›”\"] = pd.to_datetime(df[\"ì—°ì›”\"])     # 'YYYY-MM' â†’ Timestamp\n",
    "df[\"ì—°ë„\"] = df[\"ì—°ì›”\"].dt.year            # ì—°ë„ ì¶”ì¶œ\n",
    "\n",
    "# 3) ë¶„ì„ ëŒ€ìƒ ì—´(ê±°ì£¼ì¸êµ¬ ì œì™¸) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "metrics = [\n",
    "    \"ë²„ìŠ¤ìŠ¹ê°ìˆ˜\",\n",
    "    \"ì§€í•˜ì² _ìŠ¹ê°_ìˆ˜\",\n",
    "    \"ìŠ¹ê°ìˆ˜\",\n",
    "    \"ë°œìƒê±´ìˆ˜\",\n",
    "    \"ë¶€ìƒììˆ˜\",\n",
    "]\n",
    "\n",
    "# 4) ìì¹˜êµ¬Â·ì—°ë„ë³„ í•©ê³„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "yearly_by_gu = (\n",
    "    df[df[\"ì—°ë„\"].between(2017, 2023)]      # ì—°ë„ í•„í„°\n",
    "      .groupby([\"ìì¹˜êµ¬\", \"ì—°ë„\"], as_index=False)[metrics]\n",
    "      .sum()                               # ì›” â†’ ì—° í•©ê³„\n",
    ")\n",
    "\n",
    "# 5) ìˆ«ì ì—´ë§Œ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜ -------------\n",
    "yearly_by_gu[metrics] = yearly_by_gu[metrics].astype(int)\n",
    "\n",
    "# 6) ê²°ê³¼ í™•ì¸ ë˜ëŠ” ì €ì¥ -------------------\n",
    "print(yearly_by_gu.head())\n",
    "yearly_by_gu.to_csv(\"data/regression_data/passenger_data_2017_2023.csv\",\n",
    "                    index=False, encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "599b8b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì›”í‰ê·  ë°ì´í„° ì €ì¥ ì™„ë£Œ â†’ data\\first_processing_data\\population_average_2005_2023.csv\n",
      "   ìì¹˜êµ¬    ì—°ë„       ê±°ì£¼ì¸êµ¬  ë²„ìŠ¤ìŠ¹ê°ìˆ˜  ì§€í•˜ì² _ìŠ¹ê°_ìˆ˜  ìŠ¹ê°ìˆ˜  ë°œìƒê±´ìˆ˜  ë¶€ìƒììˆ˜\n",
      "0  ê°•ë‚¨êµ¬  2005       0.00    0.0       0.0  0.0   0.0   0.0\n",
      "1  ê°•ë‚¨êµ¬  2006       0.00    0.0       0.0  0.0   0.0   0.0\n",
      "2  ê°•ë‚¨êµ¬  2007       0.00    0.0       0.0  0.0   0.0   0.0\n",
      "3  ê°•ë‚¨êµ¬  2008  569166.25    0.0       0.0  0.0   0.0   0.0\n",
      "4  ê°•ë‚¨êµ¬  2009  569016.75    0.0       0.0  0.0   0.0   0.0\n",
      "5  ê°•ë‚¨êµ¬  2010  571914.50    0.0       0.0  0.0   0.0   0.0\n",
      "6  ê°•ë‚¨êµ¬  2011  575767.50    0.0       0.0  0.0   0.0   0.0\n",
      "7  ê°•ë‚¨êµ¬  2012  569638.50    0.0       0.0  0.0   0.0   0.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ğŸ“„  ìì¹˜êµ¬ Ã— ì—°ë„ë³„ ì¢…í•© ì§€í‘œ ë§Œë“¤ê¸° (2005â€“2023)\n",
    "     1) ë™ë³„ ê±°ì£¼ì¸êµ¬ ì—°ê°„ í•©ê³„ CSV  â”€â–¶  'ê±°ì£¼ì¸êµ¬'\n",
    "     2) ìì¹˜êµ¬ë³„ êµí†µÂ·ì‚¬ê³  ì—°ê°„ í•©ê³„ CSV â”€â–¶  'ë²„ìŠ¤ìŠ¹ê°ìˆ˜' ë“± 5ê°œ ì§€í‘œ\n",
    "     3) 2005~2023 ëª¨ë“  (ìì¹˜êµ¬, ì—°ë„) ì¡°í•© ìƒì„±\n",
    "     4) ê²°ì¸¡ì¹˜ëŠ” 0ìœ¼ë¡œ ì±„ìš´ ë’¤, ëª¨ë“  í•©ê³„ ê°’ì„ 12ë¡œ ë‚˜ëˆ  â€˜ì›”í‰ê· â€™ ì‚°ì¶œ\n",
    "\"\"\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 0. íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "pop_path     = Path(\"data/first_processing_data/Resident_population_preprocessing_year_sum.csv\")              # â‘  ë™ë³„ ê±°ì£¼ì¸êµ¬\n",
    "metrics_path = Path(\"data/regression_data/passenger_data_2017_2023.csv\")        # â‘¡ ìì¹˜êµ¬ë³„ êµí†µÂ·ì‚¬ê³  ì§€í‘œ\n",
    "out_path     = Path(\"data/first_processing_data/population_average_2005_2023.csv\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1. CSV ì½ê¸° & ì»¬ëŸ¼ ì •ë¦¬\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "pop_df     = pd.read_csv(pop_path, encoding=\"utf-8\").rename(columns=str.strip)\n",
    "metrics_df = pd.read_csv(metrics_path, encoding=\"utf-8\").rename(columns=str.strip)\n",
    "\n",
    "# ë™ë³„ â†’ ìì¹˜êµ¬ ì—´ ì´ë¦„ ë§ì¶”ê¸°\n",
    "pop_df = pop_df.rename(columns={\"ë™\": \"ìì¹˜êµ¬\", \"ë™ë³„\": \"ìì¹˜êµ¬\"})\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 2. 2005~2023 ì „ì²´ ìì¹˜êµ¬Â·ì—°ë„ ê·¸ë¦¬ë“œ ìƒì„±\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "years_full = range(2005, 2024)\n",
    "districts  = sorted(set(pop_df[\"ìì¹˜êµ¬\"]).union(metrics_df[\"ìì¹˜êµ¬\"]))\n",
    "\n",
    "base = (\n",
    "    pd.MultiIndex.from_product([districts, years_full], names=[\"ìì¹˜êµ¬\", \"ì—°ë„\"])\n",
    "    .to_frame(index=False)\n",
    ")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 3. ê±°ì£¼ì¸êµ¬Â·êµí†µ/ì‚¬ê³  ì§€í‘œ ë³‘í•©\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 3-1) ê±°ì£¼ì¸êµ¬\n",
    "pop_trim = pop_df[[\"ìì¹˜êµ¬\", \"ì—°ë„\", \"ê±°ì£¼ì¸êµ¬\"]]\n",
    "merged   = pd.merge(base, pop_trim, on=[\"ìì¹˜êµ¬\", \"ì—°ë„\"], how=\"left\")\n",
    "\n",
    "# 3-2) êµí†µ/ì‚¬ê³  ì§€í‘œ\n",
    "metrics_trim = metrics_df[\n",
    "    [\"ìì¹˜êµ¬\", \"ì—°ë„\", \"ë²„ìŠ¤ìŠ¹ê°ìˆ˜\", \"ì§€í•˜ì² _ìŠ¹ê°_ìˆ˜\", \"ìŠ¹ê°ìˆ˜\", \"ë°œìƒê±´ìˆ˜\", \"ë¶€ìƒììˆ˜\"]\n",
    "]\n",
    "merged = pd.merge(merged, metrics_trim, on=[\"ìì¹˜êµ¬\", \"ì—°ë„\"], how=\"left\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 4. ê²°ì¸¡ì¹˜ 0 ì±„ìš°ê¸°  â†’  ì›”í‰ê· (Ã·12) ë³€í™˜\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "numeric_cols = [\"ê±°ì£¼ì¸êµ¬\", \"ë²„ìŠ¤ìŠ¹ê°ìˆ˜\", \"ì§€í•˜ì² _ìŠ¹ê°_ìˆ˜\",\n",
    "                \"ìŠ¹ê°ìˆ˜\", \"ë°œìƒê±´ìˆ˜\", \"ë¶€ìƒììˆ˜\"]\n",
    "\n",
    "merged[numeric_cols] = (\n",
    "    merged[numeric_cols]\n",
    "      .fillna(0)         # ê²°ì¸¡ì„ 0ìœ¼ë¡œ\n",
    "      .div(12)           # ì—°ê°„ í•©ê³„ â†’ ì›”í‰ê· \n",
    "      .round(2)          # ì†Œìˆ˜ ë‘˜ì§¸ ìë¦¬\n",
    ")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 5. ì €ì¥ & í™•ì¸\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "merged.sort_values([\"ìì¹˜êµ¬\", \"ì—°ë„\"]).to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"âœ… ì›”í‰ê·  ë°ì´í„° ì €ì¥ ì™„ë£Œ â†’ {out_path}\")\n",
    "print(merged.head(8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "514b7952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       êµ¬    ì—°ë„  ë¶€ìƒììˆ˜_ì›”í‰ê·   ë°œìƒê±´ìˆ˜_ì›”í‰ê· \n",
      "0    ê°•ë‚¨êµ¬  2005    390.17    260.50\n",
      "1    ê°•ë‚¨êµ¬  2006    405.75    276.75\n",
      "2    ê°•ë‚¨êµ¬  2007    403.00    275.92\n",
      "3    ê°•ë‚¨êµ¬  2008    372.42    260.92\n",
      "4    ê°•ë‚¨êµ¬  2009    454.58    310.25\n",
      "..   ...   ...       ...       ...\n",
      "520  ì¤‘ë‘êµ¬  2021    152.17    114.42\n",
      "521  ì¤‘ë‘êµ¬  2022    157.50    116.75\n",
      "522  ì¤‘ë‘êµ¬  2023    142.00    105.67\n",
      "523  ì¤‘ë‘êµ¬  2024    135.25     99.92\n",
      "524  ì¤‘ë‘êµ¬  2025      0.00      0.00\n",
      "\n",
      "[525 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# 1. CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(\"data/merged_data/Total_updated_data.csv\")  # íŒŒì¼ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì •\n",
    "\n",
    "# 2. 'ì—°ì›”' ì»¬ëŸ¼ì—ì„œ 'ì—°ë„' ì¶”ì¶œ\n",
    "df['ì—°ë„'] = pd.to_datetime(df['ì—°ì›”']).dt.year\n",
    "\n",
    "# 3. 'êµ¬', 'ì—°ë„' ê¸°ì¤€ìœ¼ë¡œ 'ë¶€ìƒììˆ˜'ì™€ 'ë°œìƒê±´ìˆ˜' í•©ì‚°\n",
    "agg_df = df.groupby(['êµ¬', 'ì—°ë„'])[['ë¶€ìƒììˆ˜', 'ë°œìƒê±´ìˆ˜']].sum().reset_index()\n",
    "\n",
    "# 4. ì—°ê°„ í•©ê³„ë¥¼ 12ë¡œ ë‚˜ëˆ ì„œ ì›”í‰ê·  ê³„ì‚°\n",
    "agg_df['ë¶€ìƒììˆ˜_ì›”í‰ê· '] = (agg_df['ë¶€ìƒììˆ˜'] / 12).round(2)\n",
    "agg_df['ë°œìƒê±´ìˆ˜_ì›”í‰ê· '] = (agg_df['ë°œìƒê±´ìˆ˜'] / 12).round(2)\n",
    "\n",
    "# 5. í•„ìš” ì—†ëŠ” ì›ë³¸ í•©ê³„ ì»¬ëŸ¼ ì œê±° (ì„ íƒì‚¬í•­)\n",
    "agg_df = agg_df.drop(columns=['ë¶€ìƒììˆ˜', 'ë°œìƒê±´ìˆ˜'])\n",
    "\n",
    "# 6. ê²°ê³¼ í™•ì¸\n",
    "print(agg_df)\n",
    "\n",
    "agg_df.to_csv(\"data/first_processing_data/Total_average_month.csv\", index=False, encoding=\"utf-8-sig\")  # ê²°ê³¼ ì €ì¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43bdaa5-67b9-4b2d-b2e9-abff2c077532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
